{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5cda06cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): ...working... done\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Solving environment: ...working... done\n",
      "\n",
      "# All requested packages already installed.\n",
      "\n",
      "Retrieving notices: ...working... done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "==> WARNING: A newer version of conda exists. <==\n",
      "  current version: 22.9.0\n",
      "  latest version: 23.9.0\n",
      "\n",
      "Please update conda by running\n",
      "\n",
      "    $ conda update -n base -c defaults conda\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "conda install -n data_analytics_project  -c conda-forge snowflake-sqlalchemy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "909ae82f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: snowflake-sqlalchemy in c:\\users\\amrit\\anaconda3\\lib\\site-packages (1.5.0)\n",
      "Requirement already satisfied: sqlalchemy<2.0.0,>=1.4.0 in c:\\users\\amrit\\anaconda3\\lib\\site-packages (from snowflake-sqlalchemy) (1.4.32)\n",
      "Requirement already satisfied: snowflake-connector-python<4.0.0 in c:\\users\\amrit\\anaconda3\\lib\\site-packages (from snowflake-sqlalchemy) (3.2.1)\n",
      "Requirement already satisfied: asn1crypto<2.0.0,>0.24.0 in c:\\users\\amrit\\anaconda3\\lib\\site-packages (from snowflake-connector-python<4.0.0->snowflake-sqlalchemy) (1.5.1)\n",
      "Requirement already satisfied: cffi<2.0.0,>=1.9 in c:\\users\\amrit\\anaconda3\\lib\\site-packages (from snowflake-connector-python<4.0.0->snowflake-sqlalchemy) (1.15.0)\n",
      "Requirement already satisfied: cryptography<42.0.0,>=3.1.0 in c:\\users\\amrit\\anaconda3\\lib\\site-packages (from snowflake-connector-python<4.0.0->snowflake-sqlalchemy) (40.0.2)\n",
      "Requirement already satisfied: oscrypto<2.0.0 in c:\\users\\amrit\\anaconda3\\lib\\site-packages (from snowflake-connector-python<4.0.0->snowflake-sqlalchemy) (1.3.0)\n",
      "Requirement already satisfied: pyOpenSSL<24.0.0,>=16.2.0 in c:\\users\\amrit\\anaconda3\\lib\\site-packages (from snowflake-connector-python<4.0.0->snowflake-sqlalchemy) (23.2.0)\n",
      "Requirement already satisfied: pycryptodomex!=3.5.0,<4.0.0,>=3.2 in c:\\users\\amrit\\anaconda3\\lib\\site-packages (from snowflake-connector-python<4.0.0->snowflake-sqlalchemy) (3.19.0)\n",
      "Requirement already satisfied: pyjwt<3.0.0 in c:\\users\\amrit\\anaconda3\\lib\\site-packages (from snowflake-connector-python<4.0.0->snowflake-sqlalchemy) (2.1.0)\n",
      "Requirement already satisfied: pytz in c:\\users\\amrit\\anaconda3\\lib\\site-packages (from snowflake-connector-python<4.0.0->snowflake-sqlalchemy) (2022.7.1)\n",
      "Requirement already satisfied: requests<3.0.0 in c:\\users\\amrit\\anaconda3\\lib\\site-packages (from snowflake-connector-python<4.0.0->snowflake-sqlalchemy) (2.31.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\amrit\\anaconda3\\lib\\site-packages (from snowflake-connector-python<4.0.0->snowflake-sqlalchemy) (21.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\amrit\\anaconda3\\lib\\site-packages (from snowflake-connector-python<4.0.0->snowflake-sqlalchemy) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\amrit\\anaconda3\\lib\\site-packages (from snowflake-connector-python<4.0.0->snowflake-sqlalchemy) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\amrit\\anaconda3\\lib\\site-packages (from snowflake-connector-python<4.0.0->snowflake-sqlalchemy) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\amrit\\anaconda3\\lib\\site-packages (from snowflake-connector-python<4.0.0->snowflake-sqlalchemy) (2021.10.8)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.3 in c:\\users\\amrit\\anaconda3\\lib\\site-packages (from snowflake-connector-python<4.0.0->snowflake-sqlalchemy) (4.7.1)\n",
      "Requirement already satisfied: filelock<4,>=3.5 in c:\\users\\amrit\\anaconda3\\lib\\site-packages (from snowflake-connector-python<4.0.0->snowflake-sqlalchemy) (3.6.0)\n",
      "Requirement already satisfied: sortedcontainers>=2.4.0 in c:\\users\\amrit\\anaconda3\\lib\\site-packages (from snowflake-connector-python<4.0.0->snowflake-sqlalchemy) (2.4.0)\n",
      "Requirement already satisfied: platformdirs<4.0.0,>=2.6.0 in c:\\users\\amrit\\anaconda3\\lib\\site-packages (from snowflake-connector-python<4.0.0->snowflake-sqlalchemy) (3.11.0)\n",
      "Requirement already satisfied: tomlkit in c:\\users\\amrit\\anaconda3\\lib\\site-packages (from snowflake-connector-python<4.0.0->snowflake-sqlalchemy) (0.12.1)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\amrit\\anaconda3\\lib\\site-packages (from sqlalchemy<2.0.0,>=1.4.0->snowflake-sqlalchemy) (1.1.1)\n",
      "Requirement already satisfied: pycparser in c:\\users\\amrit\\anaconda3\\lib\\site-packages (from cffi<2.0.0,>=1.9->snowflake-connector-python<4.0.0->snowflake-sqlalchemy) (2.21)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\amrit\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\amrit\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\amrit\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\amrit\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\amrit\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\amrit\\anaconda3\\lib\\site-packages)\n",
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 23.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\amrit\\anaconda3\\lib\\site-packages (from packaging->snowflake-connector-python<4.0.0->snowflake-sqlalchemy) (3.0.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install snowflake-sqlalchemy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "32acdfd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\amrit\\anaconda3\\lib\\site-packages (1.3.5)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in c:\\users\\amrit\\anaconda3\\lib\\site-packages (from pandas) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.3 in c:\\users\\amrit\\anaconda3\\lib\\site-packages (from pandas) (2022.7.1)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\amrit\\anaconda3\\lib\\site-packages (from pandas) (1.24.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\amrit\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7.3->pandas) (1.16.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\amrit\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\amrit\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\amrit\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\amrit\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\amrit\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\amrit\\anaconda3\\lib\\site-packages)\n",
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 23.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8a87bde6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: snowflake-connector-python in c:\\users\\amrit\\anaconda3\\lib\\site-packages (3.2.1)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\amrit\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\amrit\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\amrit\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\amrit\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\amrit\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\amrit\\anaconda3\\lib\\site-packages)\n",
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 23.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Requirement already satisfied: asn1crypto<2.0.0,>0.24.0 in c:\\users\\amrit\\anaconda3\\lib\\site-packages (from snowflake-connector-python) (1.5.1)\n",
      "Requirement already satisfied: cffi<2.0.0,>=1.9 in c:\\users\\amrit\\anaconda3\\lib\\site-packages (from snowflake-connector-python) (1.15.0)\n",
      "Requirement already satisfied: cryptography<42.0.0,>=3.1.0 in c:\\users\\amrit\\anaconda3\\lib\\site-packages (from snowflake-connector-python) (40.0.2)\n",
      "Requirement already satisfied: oscrypto<2.0.0 in c:\\users\\amrit\\anaconda3\\lib\\site-packages (from snowflake-connector-python) (1.3.0)\n",
      "Requirement already satisfied: pyOpenSSL<24.0.0,>=16.2.0 in c:\\users\\amrit\\anaconda3\\lib\\site-packages (from snowflake-connector-python) (23.2.0)\n",
      "Requirement already satisfied: pycryptodomex!=3.5.0,<4.0.0,>=3.2 in c:\\users\\amrit\\anaconda3\\lib\\site-packages (from snowflake-connector-python) (3.19.0)\n",
      "Requirement already satisfied: pyjwt<3.0.0 in c:\\users\\amrit\\anaconda3\\lib\\site-packages (from snowflake-connector-python) (2.1.0)\n",
      "Requirement already satisfied: pytz in c:\\users\\amrit\\anaconda3\\lib\\site-packages (from snowflake-connector-python) (2022.7.1)\n",
      "Requirement already satisfied: requests<3.0.0 in c:\\users\\amrit\\anaconda3\\lib\\site-packages (from snowflake-connector-python) (2.31.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\amrit\\anaconda3\\lib\\site-packages (from snowflake-connector-python) (21.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\amrit\\anaconda3\\lib\\site-packages (from snowflake-connector-python) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\amrit\\anaconda3\\lib\\site-packages (from snowflake-connector-python) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\amrit\\anaconda3\\lib\\site-packages (from snowflake-connector-python) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\amrit\\anaconda3\\lib\\site-packages (from snowflake-connector-python) (2021.10.8)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.3 in c:\\users\\amrit\\anaconda3\\lib\\site-packages (from snowflake-connector-python) (4.7.1)\n",
      "Requirement already satisfied: filelock<4,>=3.5 in c:\\users\\amrit\\anaconda3\\lib\\site-packages (from snowflake-connector-python) (3.6.0)\n",
      "Requirement already satisfied: sortedcontainers>=2.4.0 in c:\\users\\amrit\\anaconda3\\lib\\site-packages (from snowflake-connector-python) (2.4.0)\n",
      "Requirement already satisfied: platformdirs<4.0.0,>=2.6.0 in c:\\users\\amrit\\anaconda3\\lib\\site-packages (from snowflake-connector-python) (3.11.0)\n",
      "Requirement already satisfied: tomlkit in c:\\users\\amrit\\anaconda3\\lib\\site-packages (from snowflake-connector-python) (0.12.1)\n",
      "Requirement already satisfied: pycparser in c:\\users\\amrit\\anaconda3\\lib\\site-packages (from cffi<2.0.0,>=1.9->snowflake-connector-python) (2.21)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\amrit\\anaconda3\\lib\\site-packages (from packaging->snowflake-connector-python) (3.0.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install snowflake-connector-python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a1e28ef",
   "metadata": {},
   "source": [
    "Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c42dac8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from geopy.geocoders import Nominatim\n",
    "from geopy.point import Point\n",
    "from snowflake.sqlalchemy import URL\n",
    "from sqlalchemy import create_engine\n",
    "from snowflake.connector.pandas_tools import pd_writer\n",
    "import time \n",
    "import dask.dataframe as dd\n",
    "\n",
    "# Google Maps Geocoding API\n",
    "from geopy.geocoders import GoogleV3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6514a415",
   "metadata": {},
   "source": [
    "NOTE: There is a limitation on how many times we call the geopy api in a day. We are working with only 1000 records so it is not a problem for us, however, if working with 500K or more records, run in batches multiple times taking 20K or 30K records."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f9003c7",
   "metadata": {},
   "source": [
    "NOTE: **Dask DataFrame** is a parallel and distributed computing library in Python that provides a way to work with larger-than-memory, out-of-core datasets. It is part of the Dask project, which aims to scale and parallelize various Python libraries and functions for high-performance computing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "33b97e31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 1.9342389106750488 seconds ---\n",
      "   ID                             LOCATION\n",
      "0   1                    52.23614,21.00817\n",
      "1   2                  52.336575,21.029306\n",
      "2   3  51.10710682881388,16.94346882507325\n",
      "3   4                    50.10361,20.00665\n",
      "4   5                  52.336575,21.029306\n",
      "--- 2.419481039047241 seconds ---\n",
      "   ID                             LOCATION  \\\n",
      "0   1                    52.23614,21.00817   \n",
      "1   2                  52.336575,21.029306   \n",
      "2   3  51.10710682881388,16.94346882507325   \n",
      "3   4                    50.10361,20.00665   \n",
      "4   5                  52.336575,21.029306   \n",
      "\n",
      "                                             ADDRESS  \n",
      "0         Marszałkowska 138, 00-004 Warszawa, Poland  \n",
      "1                  DW633 94, 03-044 Warszawa, Poland  \n",
      "2              Graniczna 2aa, 54-516 Wrocław, Poland  \n",
      "3  Osiedle Bohaterów Września 82P, 31-620 Kraków,...  \n",
      "4                  DW633 94, 03-044 Warszawa, Poland  \n",
      "--- 4.161579132080078 seconds ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amrit\\anaconda3\\lib\\site-packages\\pandas\\io\\sql.py:1685: UserWarning: The provided table name 'OTODOM_DATA_FLATTEN_ADDRESS' is not found exactly as such in the database after writing the table, possibly due to case sensitivity issues. Consider using lower case table names.\n",
      "  warnings.warn(msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 10.388479471206665 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "# this is a geolocator that will take longitude and latitude as an input and return address as a dictionary\n",
    "#geolocator = Nominatim(user_agent=\"otodomproject\") # this is like a user agent\n",
    "\n",
    "# since Nminatim has limited request access we will use Google Maps Geocoding API\n",
    "# Define your Google Maps API key\n",
    "api_key = 'YOUR_GOOGLE_API_KEY'\n",
    "\n",
    "# Create a Google Maps geolocator instance\n",
    "geolocator = GoogleV3(api_key=api_key)\n",
    "\n",
    "\n",
    "# Connecting Python to Snowflake\n",
    "engine = create_engine(URL(\n",
    "    account='*************',\n",
    "    user='amritaneogi',\n",
    "    password='****************',\n",
    "    database='HOUSE_PRICE',\n",
    "    schema='PUBLIC',\n",
    "    warehouse='PRICE_WH'))\n",
    "\n",
    "# Establishing a connection and creating a variable that will store the connection\n",
    "with engine.connect() as conn:\n",
    "    try:\n",
    "        # SQL query fetching the location data\n",
    "        query = \"\"\"\n",
    "            SELECT ID, concat(latitude, ',', longitude) as LOCATION\n",
    "            FROM (SELECT ID\n",
    "                , SUBSTR(location, REGEXP_INSTR(location, ' ', 1, 4) + 1) AS LATITUDE\n",
    "                , SUBSTR(location, REGEXP_INSTR(location, ' ', 1, 1) + 1, (REGEXP_INSTR(location, ' ', 1, 2) - REGEXP_INSTR(location, ' ', 1, 1) - 1)) AS LONGITUDE\n",
    "            FROM otodom_data_flatten WHERE ID between 1 and 100\n",
    "            ORDER BY ID\n",
    "            ) \"\"\"\n",
    "        print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "\n",
    "       # loading the result in a panda dataframe\n",
    "        df = pd.read_sql(query,conn) # this dataframe has 2 columns ID and Location\n",
    "        \n",
    "        # making the column names into upper case\n",
    "        # because later we use to_sql() which expects all columns to be in upper case \n",
    "        df.columns = map(lambda x: str(x).upper(), df.columns)\n",
    "\n",
    "        # loading everything from pandas dataframe to dask datafame to improve the performance\n",
    "        # dask dataframe is very similar to pandas datafame, except it can run multiple pandas dataframe parallely in a single instance\n",
    "        ddf = dd.from_pandas(df,npartitions=10) # created 10 partitions\n",
    "        print(ddf.head(5,npartitions=-1))\n",
    "\n",
    "        # Adding a 3rd column Address\n",
    "        # geolocator is an API with calls the function reverse()\n",
    "        # geolocator.reverse() accepts latitude and longitude and return a dictionary with the adress. It's going to have city, country, pincode etc.\n",
    "        # meta() will treat all the output from dask as a string\n",
    "        ddf['ADDRESS'] = ddf['LOCATION'].apply(lambda x: geolocator.reverse(x), meta=(None, 'str'))\n",
    "        # Extract relevant information and convert it to a string\n",
    "        ddf['ADDRESS'] = ddf['ADDRESS'].astype(str)\n",
    "\n",
    "        print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "\n",
    "        # We have used dask only for the above operation, since it is very expensive and takes a lot of time \n",
    "        \n",
    "        # moving the dask datafrmae to pandas dataframe\n",
    "        pandas_df = ddf.compute()  #compute() will load the data\n",
    "        print(pandas_df.head())\n",
    "        print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "\n",
    "        # Loading the data from the pandas dataframe to Snowflake\n",
    "        pandas_df.to_sql('OTODOM_DATA_FLATTEN_ADDRESS', con=engine, if_exists='append', index=False)\n",
    "\n",
    "    except Exception as e:\n",
    "        print('--- Error --- ', e)\n",
    "    finally:\n",
    "        conn.close()\n",
    "engine.dispose()\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dfa2524",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
